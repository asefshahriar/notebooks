{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1K519XcG_nxm","executionInfo":{"status":"ok","timestamp":1724772879849,"user_tz":-360,"elapsed":718,"user":{"displayName":"Asef Shahriar","userId":"15374243428059593795"}}},"outputs":[],"source":["import pandas as pd\n","import random\n","import numpy as np\n","import os\n","import cv2\n","from  matplotlib import pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90e-2UCx9Pur","outputId":"8a72a713-7fa6-44dc-dce5-d89cc46a4c87","executionInfo":{"status":"ok","timestamp":1724772917458,"user_tz":-360,"elapsed":29388,"user":{"displayName":"Asef Shahriar","userId":"15374243428059593795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyZgqfpT9mqe","outputId":"281bd725-2617-4179-8a22-7b09f151e2af"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/flood_control/new\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/flood_control/new"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmK9zscrjVDs"},"outputs":[],"source":["from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import time\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ERflxDfijWbD"},"outputs":[],"source":["data_dir = \"./\"\n","model_name = \"inception\"\n","#model_name = \"densenet\"\n","num_classes = 3\n","batch_size = 8\n","num_epochs = 15\n","feature_extract = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cI2LI66vkC2Z"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'validation']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4*loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'validation' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'validation':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pEbWUUKykDlH"},"outputs":[],"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3fd895fde7a14abab2d0f947b3090a3c","aa5306335b9c4e60bcf2c63e9484b15c","37bcb4d2713c4dd8a8865ddd0347283f","d977d580abe044c9bc92949a01c45c96","7153343213a24db3ac70439674f12279","bf91a14615f845f9b21d93b771ab5f26","b6e211899c9842df8dcbc6084de50a12","04572e6b8f1c47b79a6bb7e5222be06b","db654baf9fe7438da70f25b26f1960ef","34ec0f17f6474bfcb14a926f1b8e9864","dd923db3ed3a4735b285022d5a5c32b8"]},"id":"Ha7c2lh1kMAf","outputId":"47ed701a-473a-4444-b1e8-b11718750dcc"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/104M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd895fde7a14abab2d0f947b3090a3c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Inception3(\n","  (Conv2d_1a_3x3): BasicConv2d(\n","    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2a_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2b_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (Conv2d_3b_1x1): BasicConv2d(\n","    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_4a_3x3): BasicConv2d(\n","    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (Mixed_5b): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5c): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5d): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6a): InceptionB(\n","    (branch3x3): BasicConv2d(\n","      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6b): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6c): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6d): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6e): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (AuxLogits): InceptionAux(\n","    (conv0): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv1): BasicConv2d(\n","      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (fc): Linear(in_features=768, out_features=3, bias=True)\n","  )\n","  (Mixed_7a): InceptionD(\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7b): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7c): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",")\n"]}],"source":["def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    if model_name == \"densenet\":\n","        \"\"\" Densenet\n","        \"\"\"\n","        model_ft = models.densenet121(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        num_ftrs = model_ft.classifier.in_features\n","        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    elif model_name == \"inception\":\n","        \"\"\" Inception v3\n","        Be careful, expects (299,299) sized images and has auxiliary output\n","        \"\"\"\n","        model_ft = models.inception_v3(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model_ft, feature_extract)\n","        # Handle the auxilary net\n","        num_ftrs = model_ft.AuxLogits.fc.in_features\n","        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n","        # Handle the primary net\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n","        input_size = 299\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model_ft, input_size\n","\n","# Initialize the model for this run\n","model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","\n","# Print the model we just instantiated\n","print(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pSRTouLBHLe","outputId":"409f26c2-1faf-48dc-d9d9-9467b5ed546d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Datasets and Dataloaders...\n"]}],"source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","image_datasets = datasets.ImageFolder(data_dir, data_transforms)\n","# Create training and validation dataloaders\n","dataloaders_dict = torch.utils.data.DataLoader(image_datasets, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LIGoyYnQhIH9","outputId":"88b270a7-23d6-42e2-95c7-fd918cc3b5f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Datasets and Dataloaders...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    'train': transforms.Compose([\n","        # x = 224\n","        # x = 299\n","        transforms.Resize([int(299), int(299)]),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'validation': transforms.Compose([\n","        # x = 224\n","        #x = 299\n","        transforms.Resize([int(299), int(299)]),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create training and validation datasets\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'validation']}\n","# Create training and validation dataloaders\n","dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'validation']}\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFUzBNgPpzuV","outputId":"53286fba-55b0-43fb-f111-52bed3bd3f28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Params to learn:\n","\t AuxLogits.fc.weight\n","\t AuxLogits.fc.bias\n","\t fc.weight\n","\t fc.bias\n"]}],"source":["# Send the model to GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model_ft = model_ft.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"o_pGZBWe-Y6r","outputId":"95306171-f819-41c6-de5e-077c2c45fce5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/14\n","----------\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e19ad607c6e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"inception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-b7739d5f8ea4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_inception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0;31m# From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mInceptionOutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0maux_defined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuxLogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuxLogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;31m# N x 768 x 17 x 17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixed_7a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# N x 128 x 5 x 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;31m# N x 768 x 1 x 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# Adaptive average pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         )\n\u001b[1;32m   2435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2402\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 768, 1, 1])"]}],"source":["# Setup the loss fxn\n","criterion = nn.CrossEntropyLoss()\n","\n","# Train and evaluate\n","model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9wrK8Bk_7tb"},"outputs":[],"source":["torch.save(model_ft.state_dict(), \"dense_0.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hevxIfvAdVl"},"outputs":[],"source":["IMG_WIDTH=299\n","IMG_HEIGHT=299\n","img_folder='test'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTJponj9_zfm"},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","for i in range(10):\n","    file = random.choice(os.listdir(img_folder))\n","    im_path = os.listdir(os.path.join(img_folder, file))\n","    x = random.choice(im_path)\n","    image_path = os.path.join(img_folder, file,x)\n","    img=mpimg.imread(image_path)\n","    ax=plt.subplot(1,10,i+1)\n","    ax.title.set_text(file)\n","    plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Ky87WYG8Ibg"},"outputs":[],"source":["def create_dataset(img_folder):\n","\n","    img_data_array=[]\n","    class_name=[]\n","    im_dir_name = []\n","\n","    for dir1 in os.listdir(img_folder):\n","        for file in os.listdir(os.path.join(img_folder, dir1)):\n","\n","            image_path= os.path.join(img_folder, dir1,  file)\n","            #print(image_path)\n","            im_dir_name.append(image_path)\n","            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n","            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n","            image=np.array(image)\n","            image = image.astype('float32')\n","            image /= 255\n","            img_data_array.append(image)\n","            class_name.append(dir1)\n","    return img_data_array, class_name, im_dir_name\n","img_data, class_name, im_dir_name =create_dataset('./test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCnyGg5qGEz2"},"outputs":[],"source":["target_dict={k: v+1 for v, k in enumerate(np.unique(class_name))}\n","target_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bgePFOrHZKK"},"outputs":[],"source":["target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bfspxomHgYT"},"outputs":[],"source":["#not required\n","from sklearn.utils import shuffle\n","img, trgt = shuffle(img_data, target_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umHR_QZxrNz3"},"outputs":[],"source":["#inception v3\n","model_ft.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJmBJ9TbGM4N"},"outputs":[],"source":["#densenet\n","model_ft.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLIReeKE6K2t"},"outputs":[],"source":["def im_normalize(x):\n","  MEAN = torch.tensor([0.485, 0.456, 0.406])\n","  STD = torch.tensor([0.229, 0.224, 0.225])\n","\n","  x = torch.from_numpy(np.array(x))\n","  x = x.type(torch.float32)\n","  x = x.permute(-1, 0, 1)\n","  x = (x - MEAN[:, None, None]) / STD[:, None, None]\n","  return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phN6e2Ih0jjG"},"outputs":[],"source":["from torch.autograd import Variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-7gIHJsxQzq"},"outputs":[],"source":["inception_res = []\n","list_im = []\n","list_dir = []\n","for idx, img in enumerate(img_data):\n","    img_dict = im_normalize(img)\n","    list_dir.append(im_dir_name[idx])\n","    img = img_dict[np.newaxis,:,:,:]\n","    image_tensor = Variable(img).to(device, dtype=torch.float)\n","    sr_image = model_ft(image_tensor).cpu()\n","    probabilities = torch.nn.functional.softmax(sr_image[0], dim=0)\n","    tmp = probabilities.detach().numpy()\n","    print(tmp)\n","    inception_res.append(list(tmp).index(max(tmp))+1)\n","    list_im.append(img_dict.detach().numpy())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmAAGSTYqz_z"},"outputs":[],"source":["plt.imshow(np.einsum('kli->lik', list_im[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVdDpWSRUQ6i"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score, recall_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DX9ML3eaZ__-"},"outputs":[],"source":["#for inception\n","#for index, i in enumerate(generated_esrgan_label):\n"," # print(target_val[index], generated_esrgan_label[index])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N82OUdGwK_0B"},"outputs":[],"source":["#for densenet\n","#for index, i in enumerate(generated_esrgan_label):\n"," # print(target_val[index], generated_esrgan_label[index])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNv1BIbwbTQ8"},"outputs":[],"source":["#accuracy_score(y_true, y_pred)\n","print(\"Inception V3 evaluation metrics:\")\n","print(\"Accuracy:\", accuracy_score(target_val, inception_res))\n","print(\"F1 Score:\", f1_score(target_val, inception_res, average='macro'))\n","print(\"Precision:\", precision_score(target_val, inception_res, average='macro'))\n","print(\"Recall:\", recall_score(target_val, inception_res, average='macro'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrnAtzpXLGe2"},"outputs":[],"source":["#accuracy_score(y_true, y_pred)\n","print(\"Densenet evaluation metrics:\")\n","print(\"Accuracy:\", accuracy_score(target_val, inception_res))\n","print(\"F1 Score:\", f1_score(target_val, inception_res, average='macro'))\n","print(\"Precision:\", precision_score(target_val, inception_res, average='macro'))\n","print(\"Recall:\", recall_score(target_val, inception_res, average='macro'))"]},{"cell_type":"code","source":["#dist =[4, 7, 10, 6, 2, 8, 4, 7, 7, 4, 4, 3, 1, 4, 9, 3, 6, 2, 9, 8, 6, 6, 4, 4, 4, 9, 2, 9, 2, 6, 1, 6, 8, 6, 10, 8, 1, 10, 2, 9, 3, 6, 4, 9, 5, 10, 5, 8, 5, 6]\n","#inception_res\n","#new_inception_res = np.array(inception_res)/np.array(dist)"],"metadata":{"id":"XzUgKS3QOtxr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_inception_res = list(new_inception_res)"],"metadata":{"id":"wWemaIY-PBhr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def merge(list_im_arr, arr, l, m, r):\n","  n1 = m - l + 1\n","  n2 = r - m\n","\n","  L = [0] * (n1)\n","  LIm = [0] * (n1)\n","  R = [0] * (n2)\n","  RIm = [0] * (n2)\n","\n","  for i in range(0, n1):\n","    L[i] = arr[l + i]\n","    LIm[i] = list_im_arr[l + i]\n","\n","  for j in range(0, n2):\n","    R[j] = arr[m + 1 + j]\n","    RIm[j] = list_im_arr[m + 1 + j]\n","\n","\n","  i = 0\n","  j = 0\n","  k = l\n","\n","  while i < n1 and j < n2:\n","    if L[i] <= R[j]:\n","      arr[k] = L[i]\n","      list_im_arr[k] = LIm[i]\n","      i += 1\n","    else:\n","      arr[k] = R[j]\n","      list_im_arr[k] = RIm[j]\n","      j += 1\n","    k += 1\n","\n","  while i < n1:\n","    arr[k] = L[i]\n","    list_im_arr[k] = LIm[i]\n","    i += 1\n","    k += 1\n","\n","\n","  while j < n2:\n","    arr[k] = R[j]\n","    list_im_arr[k] = RIm[j]\n","    j += 1\n","    k += 1\n","\n","\n","\n","\n","def mergeSort(list_im_arr, arr, l, r):\n","\tif l < r:\n","\t\tm = l+(r-l)//2\n","\t\tmergeSort(list_im_arr, arr, l, m)\n","\t\tmergeSort(list_im_arr, arr, m+1, r)\n","\t\tmerge(list_im_arr, arr, l, m, r)\n","\n","\n","arr = new_inception_res\n","list_im_arr = list_dir\n","n = len(arr)\n","print(\"Given array is\")\n","for i in range(n):\n","\tprint(\"%f\" % arr[i],end=\" \")\n","print()\n","for i in list_im_arr:\n","  print(i)\n","\n","mergeSort(list_im_arr, arr, 0, n-1)\n","print(\"\\n\\nSorted array is\")\n","for i in range(n):\n","\tprint(\"%f\" % arr[i],end=\" \")\n","print()\n","for i in list_im_arr:\n","  print(i)"],"metadata":{"id":"ThDlz5w8PE5C"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rO8iatueWXfG"},"outputs":[],"source":["#densenet\n","dist =[4, 7, 10, 6, 2, 8, 4, 7, 7, 4, 4, 3, 1, 4, 9, 3, 6, 2, 9, 8, 6, 6, 4, 4, 4, 9, 2, 9, 2, 6, 1, 6, 8, 6, 10, 8, 1, 10, 2, 9, 3, 6, 4, 9, 5, 10, 5, 8, 5]\n","def mergeSort(im_arr, arr):\n","    if len(arr) > 1:\n","\n","         # Finding the mid of the array\n","        mid = len(arr)//2\n","        mid = len(im_arr)//2\n","        # Dividing the array elements\n","        L = arr[:mid]\n","        Lim = im_arr[:mid]\n","        # into 2 halves\n","        R = arr[mid:]\n","        Rim = im_arr[mid:]\n","        # Sorting the first half\n","        mergeSort(L,Lim)\n","\n","        # Sorting the second half\n","        mergeSort(R,Rim)\n","\n","        i = j = k = 0\n","\n","        # Copy data to temp arrays L[] and R[]\n","        while i < len(L) and j < len(R):\n","            if L[i] <= R[j]:\n","                arr[k] = L[i]\n","                im_arr[k] = Lim[i]\n","                i += 1\n","            else:\n","                arr[k] = R[j]\n","                im_arr[k] = Lim[i]\n","                j += 1\n","            k += 1\n","\n","        # Checking if any element was left\n","        while i < len(L):\n","            arr[k] = L[i]\n","            i += 1\n","            k += 1\n","\n","        while j < len(R):\n","            arr[k] = R[j]\n","            j += 1\n","            k += 1\n","        while i < len(Lim):\n","            im_arr[k] = Lim[i]\n","            i += 1\n","            k += 1\n","\n","        while j < len(Rim):\n","            im_arr[k] = Rim[j]\n","            j += 1\n","            k += 1\n","\n","\n","# Code to print the list\n","\n","\n","def printList(arr):\n","    for i in range(len(arr)):\n","        print(arr[i], end=\" \")\n","    print()\n","def printList(im_arr):\n","    for i in range(len(im_arr)):\n","        print(im_arr[i], end=\" \")\n","    print()\n","\n","# Driver Code\n","if __name__ == '__main__':\n","    arr = [i / j for i, j in zip(inception_res, dist)]\n","    im_arr = list_dir\n","    print(\"Given array is\", end=\"\\n\")\n","    printList(arr)\n","    printList(im_arr)\n","    mergeSort(im_arr,arr)\n","    print(\"Sorted array is: \", end=\"\\n\")\n","    printList(arr)\n","    printList(im_arr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7iyKdhrLgdy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VrcGIgyveUDM"},"outputs":[],"source":["#Inception V3\n","dist =[9,6,1,9,6,8,10,6,4,6,4,3,7,4,3,7,3,2,4,9,6,7,3,7,1,6,6,8,3,5,1,3,3,10,4,9,1,7,4,7,1,10,4,6,10,3,1,8,1,5,4,7,8,5,7,2,1,8,7,7,7,7,6,8,5,9,3,9,8,9,10,3,1,9,3,6,7,8,10,8,3,8,2,8,3,10,3,10,1,9,1,5,4,3,3,1,8,7,1,9,2,7,7,10,2,10,7,5,10,8,5,10,4,8,1,7,1,4,7,8,8,5,1,10,3,6,9,2,4,3,7,3,9,10,8,1,3,2,7,8,9,5,3,3,7,3,6,7,7,9,9,8,9,9,5,9,8,7,5,7,10]\n","def merge(list_im_arr, arr, l, m, r):\n","  n1 = m - l + 1\n","  n2 = r - m\n","\n","  L = [0] * (n1)\n","  LIm = [0] * (n1)\n","  R = [0] * (n2)\n","  RIm = [0] * (n2)\n","\n","  for i in range(0, n1):\n","    L[i] = arr[l + i]\n","    LIm[i] = list_im_arr[l + i]\n","\n","  for j in range(0, n2):\n","    R[j] = arr[m + 1 + j]\n","    RIm[j] = list_im_arr[m + 1 + j]\n","\n","\n","  i = 0\n","  j = 0\n","  k = l\n","\n","  while i < n1 and j < n2:\n","    if L[i] <= R[j]:\n","      arr[k] = L[i]\n","      list_im_arr[k] = LIm[i]\n","      i += 1\n","    else:\n","      arr[k] = R[j]\n","      list_im_arr[k] = RIm[j]\n","      j += 1\n","    k += 1\n","\n","  while i < n1:\n","    arr[k] = L[i]\n","    list_im_arr[k] = LIm[i]\n","    i += 1\n","    k += 1\n","\n","\n","  while j < n2:\n","    arr[k] = R[j]\n","    list_im_arr[k] = RIm[j]\n","    j += 1\n","    k += 1\n","\n","\n","\n","\n","def mergeSort(list_im_arr, arr, l, r):\n","\tif l < r:\n","\t\tm = l+(r-l)//2\n","\t\tmergeSort(list_im_arr, arr, l, m)\n","\t\tmergeSort(list_im_arr, arr, m+1, r)\n","\t\tmerge(list_im_arr, arr, l, m, r)\n","\n","\n","arr = [x/y for x, y in zip(map(float, inception_res), map(float, dist))]\n","list_im_arr = list_dir\n","n = len(arr)\n","print(inception_res)\n","print(\"Given array is\")\n","for i in range(n):\n","\tprint(\"%f\" % arr[i],end=\" \")\n","print()\n","for i in list_im_arr:\n","  print(i)\n","\n","mergeSort(list_im_arr, arr, 0, n-1)\n","print(\"\\n\\nSorted array is\")\n","for i in range(n):\n","\tprint(\"%f\" % arr[i],end=\" \")\n","print()\n","for i in list_im_arr:\n","  print(i)"]},{"cell_type":"code","source":["target_val"],"metadata":{"id":"BAo8ciDfQjlh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","import pandas as pd\n","\n","\n","# constant for classes\n","classes = ('Major_flooding', 'Moderate_flooding', 'Minor_flooding')\n","\n","# Build confusion matrix\n","cf_matrix = confusion_matrix(target_val, inception_res)\n","dataframe = pd.DataFrame(cf_matrix, index=classes, columns=classes)\n","plt.figure(figsize=(10, 8))\n","\n","# Create heatmap\n","sn.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n","\n","plt.title(\"Confusion Matrix\"), plt.tight_layout()\n","\n","plt.ylabel(\"True Class\"),\n","plt.xlabel(\"Predicted Class\")\n","plt.show()\n","plt.savefig('confusematrx.png')"],"metadata":{"id":"cQ04ltdhWA8K"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3fd895fde7a14abab2d0f947b3090a3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa5306335b9c4e60bcf2c63e9484b15c","IPY_MODEL_37bcb4d2713c4dd8a8865ddd0347283f","IPY_MODEL_d977d580abe044c9bc92949a01c45c96"],"layout":"IPY_MODEL_7153343213a24db3ac70439674f12279"}},"aa5306335b9c4e60bcf2c63e9484b15c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf91a14615f845f9b21d93b771ab5f26","placeholder":"","style":"IPY_MODEL_b6e211899c9842df8dcbc6084de50a12","value":"100%"}},"37bcb4d2713c4dd8a8865ddd0347283f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04572e6b8f1c47b79a6bb7e5222be06b","max":108949747,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db654baf9fe7438da70f25b26f1960ef","value":108949747}},"d977d580abe044c9bc92949a01c45c96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34ec0f17f6474bfcb14a926f1b8e9864","placeholder":"","style":"IPY_MODEL_dd923db3ed3a4735b285022d5a5c32b8","value":" 104M/104M [00:04&lt;00:00, 25.4MB/s]"}},"7153343213a24db3ac70439674f12279":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf91a14615f845f9b21d93b771ab5f26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6e211899c9842df8dcbc6084de50a12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04572e6b8f1c47b79a6bb7e5222be06b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db654baf9fe7438da70f25b26f1960ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34ec0f17f6474bfcb14a926f1b8e9864":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd923db3ed3a4735b285022d5a5c32b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}