{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6tTZLn6yZCjLc4i4BETb5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzFQQ3N8h0WG","executionInfo":{"status":"ok","timestamp":1716367891755,"user_tz":-360,"elapsed":7903,"user":{"displayName":"Asef Shahriar","userId":"15374243428059593795"}},"outputId":"c0b73491-6cad-4463-96fb-9635ed275ddf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (1.6.2)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from autograd) (1.25.2)\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd) (0.18.3)\n"]}],"source":["!pip install autograd\n","import autograd.numpy as np\n","import matplotlib.pyplot as plt\n","from autograd import grad"]},{"cell_type":"code","source":["def generate_nonlinear_data(num_points, slope, intercept, noise_level):\n","  \"\"\"\n","  Generates a linear dataset with noise.\n","\n","  Parameters:\n","      num_points: Number of data points to generate.\n","      slope: Slope of the linear relationship.\n","      intercept: Intercept of the linear relationship.\n","      noise_level: Level of random noise to add to the data.\n","\n","  Returns:\n","      x_vals: Array of x values.\n","      y_vals: Array of corresponding y values.\n","  \"\"\"\n","  x_vals = np.linspace(0, 10, num_points)\n","  noise = noise_level * np.random.normal(size=num_points)\n","  y_vals = slope * x_vals + intercept + noise\n","  return x_vals, y_vals\n","\n","def save_data_to_csv(data, filename):\n","  \"\"\"\n","  Saves data to a CSV file.\n","\n","  Args:\n","      data: List of lists containing the data to save.\n","      filename: Name of the CSV file.\n","  \"\"\"\n","  with open(filename, 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerows(data)  # Write all rows at once\n","\n","def load_data_from_csv(filename):\n","  \"\"\"\n","  Loads data from a CSV file.\n","\n","  Args:\n","      filename: Name of the CSV file.\n","\n","  Returns:\n","      A list of lists containing the data from the CSV file.\n","  \"\"\"\n","  with open(filename, 'r') as csvfile:\n","    reader = csv.reader(csvfile)\n","    return list(reader)"],"metadata":{"id":"6npZHcUdiWH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Layer:\n","  def __init__(self):\n","    self.inputs = None\n","    self.output = None\n","\n","  def forward(self, inputs):\n","    raise NotImplementedError\n","\n","  def backward(self, loss, lr):\n","    raise NotImplementedError\n","\n","\n","#Dense layer\n","class Layer_Dense(Layer):\n","  def __init__(self, n_inputs, n_neurons):\n","    # Initialize weights and biases\n","    self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n","    self.biases = np.zeros((1, n_neurons))\n","\n","  # Forward pass\n","  def forward(self, inputs):\n","    self.inputs = inputs\n","    self.output = np.dot(inputs, self.weights) + self.biases\n","\n","  def backward(self, loss, lr):\n","    \"\"\"\n","    Performs the backward pass of the dense layer.\n","\n","    Args:\n","      loss: The gradient of the loss function with respect to the layer's output.\n","      lr: The learning rate.\n","    \"\"\"\n","    # Calculate the gradient of the loss with respect to the weights and biases\n","    d_loss_d_weights = np.dot(self.inputs, loss)\n","    d_loss_d_biases = np.sum(loss, axis=0, keepdims=True)\n","\n","    # Update weights and biases using gradient descent\n","    self.weights -= lr * d_loss_d_weights\n","    self.biases -= lr * d_loss_d_biases"],"metadata":{"id":"z2MdE1b5Xjqq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NeuralNetwork:\n","  def __init__(self, layers):\n","    self.layers = layers\n","\n","  def forward(self, X):\n","    \"\"\"\n","    Performs forward pass through all layers in the network.\n","\n","    Args:\n","      X: Input data.\n","\n","    Returns:\n","      Output of the final layer.\n","    \"\"\"\n","    for layer in self.layers:\n","      X = layer.forward(X)\n","    return X\n","\n","  def backward(self, loss, lr):\n","    \"\"\"\n","    Performs backward pass through all layers to update weights and biases.\n","\n","    Args:\n","      loss: Loss function value.\n","      lr: Learning rate.\n","    \"\"\"\n","    # Propagate loss backwards through layers\n","    grad_loss = 1.0  # Initial gradient for output layer\n","    for layer in reversed(self.layers):\n","      grad_loss = layer.backward(grad_loss, lr)\n","\n","# Example usage\n","# Define layers (replace with your desired network architecture)\n","layer1 = Layer_Dense(1, 32)  # Input layer with 784 neurons, 32 hidden neurons\n","layer2 = Layer_Dense(32, 1)   # Output layer with 10 neurons (e.g., for 10 class labels)\n","\n","# Create the neural network\n","network = NeuralNetwork([layer1, layer2])\n","\n","# Train the network (replace with your training data and loss function)\n","X_train = [1,2,3,4,5]  # Your training data\n","y_train = [1,4,9,16,25]  # Your training labels\n","def loss_function(predicted_y, y):\n","  return np.mean((y - predicted_y)**2)\n","\n","\n","for epoch in range(100):\n","  for i in range(len(X_train)):\n","    X = X_train[i]\n","    y = y_train[i]\n","\n","    # Forward pass\n","    predicted_y = network.forward(X)\n","\n","    # Calculate loss\n","    loss = loss_function(predicted_y, y)\n","\n","    # Backward pass\n","    network.backward(loss, 0.01)  # Update weights with learning rate of 0.01\n","\n","# Now you have a trained neural network in the 'network' variable\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"9dIpRkztY3Rf","executionInfo":{"status":"error","timestamp":1716369657611,"user_tz":-360,"elapsed":4,"user":{"displayName":"Asef Shahriar","userId":"15374243428059593795"}},"outputId":"a6fdf8c1-4bea-48a5-ae3c-efbe92d78f40"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for *: 'NoneType' and 'float'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-5232b2c27216>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mpredicted_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-5232b2c27216>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-1e5f12afb4c5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"o3bZ8zzhf13h"},"execution_count":null,"outputs":[]}]}